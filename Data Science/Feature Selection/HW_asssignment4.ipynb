{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bf6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29843b90",
   "metadata": {},
   "source": [
    "<h2> Feature Selection on OnlineNewsPopularity </h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d2aa2b8",
   "metadata": {},
   "source": [
    "<h3>Exercise</h3>\n",
    "\n",
    "\n",
    "1. Load the \"OnlineNewsPopularity.csv\" dataset \n",
    "2. Drop the Column which isn't required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4647c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file from the link provided\n",
    "# drop the column that is not required from the dataset(url)\n",
    "df = pd.read_csv(\"OnlineNewsPopularity.csv\", delimiter=', ', engine=\"python\")\n",
    "df = df.drop(['url'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5ddda51",
   "metadata": {},
   "source": [
    "<h3>Exercise</h3>\n",
    "\n",
    "\n",
    "1. Scale the data using a appropriate scaler and re-asign the column names after scaling.\n",
    "2. The function below should return scaled result in the form of DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4efdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: Use MinMaxScaler for scaling\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c618794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd4d64",
   "metadata": {},
   "source": [
    "5. Perform train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2c41cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, :'abs_title_sentiment_polarity']\n",
    "y = df['shares']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=50)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_train = y_train.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ae893",
   "metadata": {},
   "source": [
    "6. Write a function which returns the list of k-Best features where k being the number of features required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7067f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use chi2\n",
    "def get_k_best_features(X, y, k):\n",
    "    k_best = SelectKBest(score_func=chi2, k=k)\n",
    "    k_best.fit(X, y)\n",
    "    return list(X.columns[k_best.get_support()])\n",
    "\n",
    "selected_features = get_k_best_features(df_scaled, y, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdeb22c",
   "metadata": {},
   "source": [
    "Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30bc26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_channel_is_entertainment', 'data_channel_is_world', 'weekday_is_saturday', 'is_weekend', 'shares']\n"
     ]
    }
   ],
   "source": [
    "# return the top N features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256fe12",
   "metadata": {},
   "source": [
    "<h2> Model selection on Algerian_forest_fires_dataset_UPDATE-1 dataset  </h2>\n",
    "<h3>Exercise (Hint use Ridge and Lasso to compare the models.)</h3>\n",
    "\n",
    "<p>Your task is to findout which of the above models is best suited for the given dataset and give reasons in this scenario. </p>\n",
    "<p>Also, you need to give scenarios which each of these Models work better over the other.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a0d47",
   "metadata": {},
   "source": [
    "1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54906802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day', 'month', 'year', 'Temperature', 'RH', 'Ws', 'Rain', 'FFMC',\n",
      "       'DMC', 'DC', 'ISI', 'BUI', 'FWI', 'Classes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and split into training and test sets\n",
    "data = pd.read_csv(\"Algerian_forest_fires_dataset_UPDATE-1.csv\", delimiter=',', engine=\"python\")\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# convert 'Classes' column to numeric (0 for 'not fire' and 1 for 'fire')\n",
    "data['Classes'] = data['Classes'].str.strip()\n",
    "data['Classes'] = data['Classes'].replace('not fire', 0)\n",
    "data['Classes'] = data['Classes'].replace('fire', 1)\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f68a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[124:]\n",
    "df = pd.concat([data.loc[:120], data.loc[125:]])\n",
    "df['Classes'] = df['Classes'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "870e1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() # label encoder\n",
    "le.fit(df['Classes']) # fit the label encoder\n",
    "df['Classes'] = le.transform(df['Classes']) # transform the labels\n",
    "\n",
    "X = df.loc[:,:'Rain'] # Rain may be a good feature to predict fires\n",
    "y = df['Classes'] # Classes is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049765d5",
   "metadata": {},
   "source": [
    "* Drop the unnecessary columns and use train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cf11217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Lasso: 0.15973\n",
      "MSE for Ridge: 0.14597\n"
     ]
    }
   ],
   "source": [
    "# Your task is to findout which of the above models is best suited for the given dataset and give reasons in this scenario.\n",
    "# you need to give scenarios which each of these Models work better over the other\n",
    "kbest = SelectKBest(score_func=chi2, k=5)\n",
    "kbest.fit(X_train, y_train)\n",
    "\n",
    "X_train_kbest = kbest.transform(X_train)\n",
    "X_test_kbest = kbest.transform(X_test)\n",
    "\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100), n_features_to_select=5)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"MSE for Lasso: {:.5f}\".format(mse_lasso))\n",
    "print(\"MSE for Ridge: {:.5f}\".format(mse_ridge))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3d0d02c",
   "metadata": {},
   "source": [
    "In this scenario, we have built two different feature selection models: a filter method based on correlation coefficient and a wrapper method based on recursive feature elimination with cross-validation. Now, we want to compare Lasso and Ridge regression models to see which one is better suited for this dataset.\n",
    "\n",
    "Lasso regression is a linear regression model that adds an L1 penalty term to the loss function to encourage sparsity in the coefficients. It can be useful when we have many irrelevant or redundant features that we want to eliminate from the model. Lasso can perform well in situations where we expect only a few important features to have a strong effect on the target variable.\n",
    "\n",
    "Ridge regression is another linear regression model that adds an L2 penalty term to the loss function. Unlike Lasso, Ridge regression does not necessarily encourage sparsity in the coefficients. It can be useful when we have many important features with small coefficients that we do not want to eliminate completely.\n",
    "\n",
    "Therefore, in scenarios where we have many irrelevant or redundant features, Lasso regression may perform better than Ridge regression. On the other hand, in scenarios where we have many important features with small coefficients, Ridge regression may be more appropriate. Ultimately, the choice between Lasso and Ridge regression will depend on the specific characteristics of the dataset and the goals of the modeling project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
